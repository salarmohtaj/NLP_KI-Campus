{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Text Vectorization with Scikit-learn\n",
    "\n",
    "This notebook demonstrates how to vectorize text data using different methods provided by the `scikit-learn` library:\n",
    "\n",
    "- Count Vectorizer (Bag of Words)\n",
    "- n-grams\n",
    "- TF-IDF"
   ],
   "id": "5fb6e04f7d59a1e3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Preparing the Data\n",
    "\n",
    "We will use a small set of sample text data for this demonstration.\n"
   ],
   "id": "85dd1a714fd89662"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-07T00:52:40.679152Z",
     "start_time": "2025-01-07T00:52:38.769824Z"
    }
   },
   "source": [
    "%pip install sklearn\n",
    "\n",
    "# Sample text data\n",
    "documents = [\n",
    "    \"Natural language processing is fun and exciting.\",\n",
    "    \"Machine learning is a part of data science.\",\n",
    "    \"Data science involves statistics and programming.\",\n",
    "    \"Python is a great programming language for machine learning.\"\n",
    "]\n",
    "\n",
    "# Display the data\n",
    "for i, doc in enumerate(documents, 1):\n",
    "    print(f\"Document {i}: {doc}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\r\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001B[?25lerror\r\n",
      "  \u001B[1;31merror\u001B[0m: \u001B[1msubprocess-exited-with-error\u001B[0m\r\n",
      "  \r\n",
      "  \u001B[31m×\u001B[0m \u001B[32mpython setup.py egg_info\u001B[0m did not run successfully.\r\n",
      "  \u001B[31m│\u001B[0m exit code: \u001B[1;36m1\u001B[0m\r\n",
      "  \u001B[31m╰─>\u001B[0m \u001B[31m[15 lines of output]\u001B[0m\r\n",
      "  \u001B[31m   \u001B[0m The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\r\n",
      "  \u001B[31m   \u001B[0m rather than 'sklearn' for pip commands.\r\n",
      "  \u001B[31m   \u001B[0m \r\n",
      "  \u001B[31m   \u001B[0m Here is how to fix this error in the main use cases:\r\n",
      "  \u001B[31m   \u001B[0m - use 'pip install scikit-learn' rather than 'pip install sklearn'\r\n",
      "  \u001B[31m   \u001B[0m - replace 'sklearn' by 'scikit-learn' in your pip requirements files\r\n",
      "  \u001B[31m   \u001B[0m   (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\r\n",
      "  \u001B[31m   \u001B[0m - if the 'sklearn' package is used by one of your dependencies,\r\n",
      "  \u001B[31m   \u001B[0m   it would be great if you take some time to track which package uses\r\n",
      "  \u001B[31m   \u001B[0m   'sklearn' instead of 'scikit-learn' and report it to their issue tracker\r\n",
      "  \u001B[31m   \u001B[0m - as a last resort, set the environment variable\r\n",
      "  \u001B[31m   \u001B[0m   SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\r\n",
      "  \u001B[31m   \u001B[0m \r\n",
      "  \u001B[31m   \u001B[0m More information is available at\r\n",
      "  \u001B[31m   \u001B[0m https://github.com/scikit-learn/sklearn-pypi-package\r\n",
      "  \u001B[31m   \u001B[0m \u001B[31m[end of output]\u001B[0m\r\n",
      "  \r\n",
      "  \u001B[1;35mnote\u001B[0m: This error originates from a subprocess, and is likely not a problem with pip.\r\n",
      "\u001B[1;31merror\u001B[0m: \u001B[1mmetadata-generation-failed\u001B[0m\r\n",
      "\r\n",
      "\u001B[31m×\u001B[0m Encountered error while generating package metadata.\r\n",
      "\u001B[31m╰─>\u001B[0m See above for output.\r\n",
      "\r\n",
      "\u001B[1;35mnote\u001B[0m: This is an issue with the package mentioned above, not pip.\r\n",
      "\u001B[1;36mhint\u001B[0m: See above for details.\r\n",
      "\u001B[?25hNote: you may need to restart the kernel to use updated packages.\n",
      "Document 1: Natural language processing is fun and exciting.\n",
      "Document 2: Machine learning is a part of data science.\n",
      "Document 3: Data science involves statistics and programming.\n",
      "Document 4: Python is a great programming language for machine learning.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Count Vectorizer (Bag of Words)\n",
    "Count Vectorizer converts text into a matrix of token counts.\n",
    "\n",
    "python\n",
    "Copy code\n"
   ],
   "id": "770009e74f6acc05"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T00:52:07.479522Z",
     "start_time": "2025-01-07T00:52:07.002572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the text data\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Display the feature names (words)\n",
    "print(\"Feature Names:\", vectorizer.get_feature_names_out())\n",
    "\n",
    "# Display the Bag of Words matrix\n",
    "print(\"\\nBag of Words Matrix:\")\n",
    "print(X.toarray())"
   ],
   "id": "ce83e62e47e90edc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Names: ['and' 'data' 'exciting' 'for' 'fun' 'great' 'involves' 'is' 'language'\n",
      " 'learning' 'machine' 'natural' 'of' 'part' 'processing' 'programming'\n",
      " 'python' 'science' 'statistics']\n",
      "\n",
      "Bag of Words Matrix:\n",
      "[[1 0 1 0 1 0 0 1 1 0 0 1 0 0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 1 0 1 1 0 1 1 0 0 0 1 0]\n",
      " [1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1]\n",
      " [0 0 0 1 0 1 0 1 1 1 1 0 0 0 0 1 1 0 0]]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Using n-grams\n",
    "An n-gram is a sequence of n words. Here, we demonstrate bi-grams (n=2)."
   ],
   "id": "87d4b0bc41ac6e14"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T00:53:30.299905Z",
     "start_time": "2025-01-07T00:53:30.285357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Configure the CountVectorizer for bi-grams\n",
    "bigram_vectorizer = CountVectorizer(ngram_range=(2, 2))\n",
    "\n",
    "# Fit and transform the text data\n",
    "X_bigram = bigram_vectorizer.fit_transform(documents)\n",
    "\n",
    "# Display the feature names (bi-grams)\n",
    "print(\"Bi-gram Feature Names:\", bigram_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Display the bi-gram matrix\n",
    "print(\"\\nBi-gram Matrix:\")\n",
    "print(X_bigram.toarray())\n"
   ],
   "id": "b3e308b7128c35e2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bi-gram Feature Names: ['and exciting' 'and programming' 'data science' 'for machine' 'fun and'\n",
      " 'great programming' 'involves statistics' 'is fun' 'is great' 'is part'\n",
      " 'language for' 'language processing' 'learning is' 'machine learning'\n",
      " 'natural language' 'of data' 'part of' 'processing is'\n",
      " 'programming language' 'python is' 'science involves' 'statistics and']\n",
      "\n",
      "Bi-gram Matrix:\n",
      "[[1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 0]\n",
      " [0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1]\n",
      " [0 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0]]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. TF-IDF Vectorization\n",
    "TF-IDF (Term Frequency-Inverse Document Frequency) gives importance to words based on their frequency across the documents."
   ],
   "id": "d1ee6ed046732abf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T00:53:52.955275Z",
     "start_time": "2025-01-07T00:53:52.943983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the text data\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(documents)\n",
    "\n",
    "# Display the feature names (words)\n",
    "print(\"TF-IDF Feature Names:\", tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Display the TF-IDF matrix\n",
    "print(\"\\nTF-IDF Matrix:\")\n",
    "print(X_tfidf.toarray())\n"
   ],
   "id": "4db9851625d679cc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Feature Names: ['and' 'data' 'exciting' 'for' 'fun' 'great' 'involves' 'is' 'language'\n",
      " 'learning' 'machine' 'natural' 'of' 'part' 'processing' 'programming'\n",
      " 'python' 'science' 'statistics']\n",
      "\n",
      "TF-IDF Matrix:\n",
      "[[0.33166972 0.         0.42068099 0.         0.42068099 0.\n",
      "  0.         0.26851522 0.33166972 0.         0.         0.42068099\n",
      "  0.         0.         0.42068099 0.         0.         0.\n",
      "  0.        ]\n",
      " [0.         0.35639424 0.         0.         0.         0.\n",
      "  0.         0.28853185 0.         0.35639424 0.35639424 0.\n",
      "  0.4520409  0.4520409  0.         0.         0.         0.35639424\n",
      "  0.        ]\n",
      " [0.37222485 0.37222485 0.         0.         0.         0.\n",
      "  0.47212003 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.37222485 0.         0.37222485\n",
      "  0.47212003]\n",
      " [0.         0.         0.         0.41191063 0.         0.41191063\n",
      "  0.         0.26291722 0.32475507 0.32475507 0.32475507 0.\n",
      "  0.         0.         0.         0.32475507 0.41191063 0.\n",
      "  0.        ]]\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
